{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "524edf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fd9445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f51e96e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLES ={\n",
    "   \"1\":{\n",
    "       \"name\":\"倫理エキスパート\",\n",
    "       \"description\":\"倫理的な観点からチェックするエキスパート\",\n",
    "       \"details\":\"倫理的な観点に関する知識が豊富で、文面の内容が倫理的な観点から問題ないかを評価できます。\"\n",
    "   },\n",
    "   \"2\":{\n",
    "       \"name\":\"技術エキスパート\",\n",
    "       \"description\":\"技術的な質問に答えることが得意なエキスパートです。\",\n",
    "       \"details\":\"プログラミング、ソフトウェア開発、ITインフラストラクチャなどの技術分野に精通しており、専門的な質問に対応できます。\"\n",
    "   },\n",
    "   \"3\":{\n",
    "       \"name\":\"ビジネスエキスパート\",\n",
    "       \"description\":\"ビジネスに関する質問に答えることが得意なエキスパートです。\",\n",
    "       \"details\":\"マーケティング、戦略、経営などのビジネス分野に精通しており、実践的なアドバイスを提供できます。\"\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cfbe92dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d2470bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 状態遷移を保持するクラス\n",
    "class State(BaseModel):\n",
    "    query: str = Field(\n",
    "        description=\"ユーザーからの質問\"\n",
    "    )\n",
    "    current_role: str = Field(\n",
    "        default=\"\",\n",
    "        description=\"選定された回答ロール\"\n",
    "    )\n",
    "    # add operator で、リストを結合するおかげですべてのメッセージが State に保持される\n",
    "    messages: Annotated[list[str], operator.add] = Field(\n",
    "        default=[], description=\"回答履歴\"\n",
    "    )\n",
    "    judgement_result: bool = Field(\n",
    "        default=False,\n",
    "        description=\"品質チェックの結果\"\n",
    "    )\n",
    "    judgement_reason: str = Field(\n",
    "        default=\"\",\n",
    "        description=\"品質チェックの理由\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7e39f835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure OpenAI のインスタンスを準備\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from azure.identity import ClientSecretCredential, get_bearer_token_provider\n",
    "\n",
    "token_provider = get_bearer_token_provider(\n",
    "    ClientSecretCredential(\n",
    "        client_id=os.getenv(\"client_id\"),\n",
    "        client_secret=os.getenv(\"client_secret\"),\n",
    "        tenant_id=os.getenv(\"tenant_id\")\n",
    "    ),\n",
    "    \"https://cognitiveservices.azure.com/.default\"\n",
    ")\n",
    "aoai = AzureChatOpenAI(\n",
    "    azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    api_version=\"2025-02-01-preview\",\n",
    "    azure_ad_token_provider=token_provider,\n",
    "    temperature=0\n",
    ")\n",
    "# 後からパラメータを変更できるように ConfigurableField でラップ\n",
    "aoai = aoai.configurable_fields(max_tokens=ConfigurableField(id='max_tokens'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d33705a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hi there! 😊 How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 9, 'total_tokens': 21, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_3eed281ddb', 'id': 'chatcmpl-CDVfEHPQgYvLLCghQLmtivFolyuDh', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run--51b43e85-981a-4467-bacd-ed2c5d6ce079-0', usage_metadata={'input_tokens': 9, 'output_tokens': 12, 'total_tokens': 21, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aoai.invoke([{\"role\":\"user\",\"content\":\"Hello!\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "04e580f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def selection_node(state: State) -> str:\n",
    "    # まずは、state に保存されている現在のクエリを与える\n",
    "    query = state.query\n",
    "    # \\n(改行) で ROLES の内容を連結して文字列にする（あとで LLM に渡すため）\n",
    "    role_options = \"\\n\".join([f\"{k}:{v['name']} - {v['description']}\" for k,v in ROLES.items()])\n",
    "    # LLM に与えるプロンプトを作成\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"あなたは優秀なアシスタントです。以下の質問に最も適したエキスパートを選んでください。\n",
    "\n",
    "        質問: {query}\n",
    "\n",
    "        選択肢:\n",
    "        {role_options}\n",
    "        \n",
    "        回答は選択肢の番号(1,2,3)のどれかのみ返してください。\n",
    "        \"\"\".strip()\n",
    "    )\n",
    "    # 選択肢の番号のみを返すように設定したいため、max_tokens を 1 に設定\n",
    "    chain = prompt | aoai.with_config(configurable=dict(max_tokens=1)) | StrOutputParser()\n",
    "    selected_role_num = chain.invoke({\"query\": query, \"role_options\": role_options}).strip()\n",
    "    selected_role = ROLES[selected_role_num][\"name\"] \n",
    "    return {\"current_role\": selected_role}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f4d54985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function print(*args, sep=' ', end='\\n', file=None, flush=False)>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ROLES['1'])\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d1a0e05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answering_node(state: State) -> dict[str, Any]:\n",
    "    query = state.query\n",
    "    role = state.current_role\n",
    "    # current role に基づいて LLM が回答するため、説明としては全ロールの説明を入れておく必要がある\n",
    "    role_options = \"\\n\".join([f\"-{v['name']} - {v['description']}\" for v in ROLES.values()])\n",
    "    # 静的に変数として role_num を受け取っていれば、以下のように書けるが、今回は書籍に合わせる\n",
    "    # role_detail = f\"-{role['name']}: {role['description']}\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"あなたは {role} として回答してください。また回答の最初に自分がどのロールで回答しているかを明記してください。\n",
    "        \n",
    "        ロール定義\n",
    "        {role_options}\n",
    "        \n",
    "        質問: {query}\n",
    "        \n",
    "        回答:\n",
    "        \"\"\".strip()\n",
    "    )\n",
    "    chain = prompt | aoai | StrOutputParser()\n",
    "    ans = chain.invoke({\"query\": query, \"role\": role, \"role_options\": role_options})\n",
    "    return {\"messages\": [ans]}  # messages は list[str] なので、list にして返す -> 戻り値を受け取った側で append するため\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ae974f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Judgement(BaseModel):\n",
    "    reason: str = Field(\n",
    "        description=\"品質チェックの理由\",\n",
    "        default=\"\"\n",
    "    )\n",
    "    judge: bool = Field(\n",
    "        description=\"品質チェックの結果\",\n",
    "        default=False\n",
    "    )\n",
    "\n",
    "def check_node(state: State) -> dict[str, Any]:\n",
    "    query = state.query\n",
    "    answer = state.messages[-1]  # 最新の回答を取得\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "                                              以下の回答をチェックし、品質に問題がある場合は、'False'、問題がない場合は 'True' を返してください。\n",
    "                                              \n",
    "                                                質問: {query}\n",
    "                                                回答: {answer}\n",
    "                                              \n",
    "                                              \"\"\".strip())\n",
    "    chain = prompt | aoai.with_structured_output(Judgement) \n",
    "    result:Judgement = chain.invoke({\"query\": query, \"answer\": answer})\n",
    "    return {\n",
    "        \"judgement_reason\": result.reason,\n",
    "        \"judgement_result\": result.judge\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "be2e72c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "workflow = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7377ab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "workflow.add_node(\"selection\", selection_node)\n",
    "workflow.add_node(\"answering\", answering_node)\n",
    "workflow.add_node(\"check\", check_node)\n",
    "\n",
    "workflow.set_entry_point(\"selection\")\n",
    "workflow.add_edge(\"selection\", \"answering\")\n",
    "workflow.add_edge(\"answering\", \"check\")\n",
    "workflow.add_conditional_edges(\"check\", lambda state: state.judgement_result, {True: END, False: \"selection\"})\n",
    "\n",
    "compiled = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "40072fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\koishizu\\AppData\\Local\\anaconda3\\envs\\langgraph_env\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1896: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "init_state = State(query=\"医療業界において生成AIを用いたビジネスを生み出そうとした際に、どのようなものが考えられますか？データのプライバシーや倫理的な観点も考慮してください。\")\n",
    "result = compiled.invoke(init_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5e7c29f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['**ビジネスエキスパートとして回答します。**\\n'\n",
      " '\\n'\n",
      " '医療業界において生成AIを活用したビジネスを構築する際には、以下のようなアイデアが考えられます。ただし、データのプライバシーや倫理的な観点を十分に考慮する必要があります。\\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### 1. **患者向けのパーソナライズド健康アドバイザー**\\n'\n",
      " '生成AIを活用して、患者の健康データ（例：電子カルテ、ウェアラブルデバイスのデータ）を分析し、個別化された健康アドバイスを提供するサービスを構築できます。たとえば、食事、運動、睡眠の改善提案や、慢性疾患の管理サポートなどが挙げられます。\\n'\n",
      " '\\n'\n",
      " '- **ビジネスメリット**: 健康意識の高まりに伴い、個別化されたサービスの需要が増加。\\n'\n",
      " '- **倫理的配慮**: 患者データの匿名化、データ利用の透明性、AIのアドバイスが医療行為と誤解されないよう明確化。\\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### 2. **医療従事者向けの診断支援ツール**\\n'\n",
      " '生成AIを用いて、医師や看護師が診断や治療計画を立てる際のサポートを行うツールを開発します。例えば、患者の症状や検査結果を入力すると、AIが考えられる診断候補や治療オプションを提示する仕組みです。\\n'\n",
      " '\\n'\n",
      " '- **ビジネスメリット**: 医療従事者の負担軽減、診断精度の向上。\\n'\n",
      " '- **倫理的配慮**: AIの診断結果が医師の判断を完全に代替するものではないことを明確化。誤診リスクを最小化するための検証プロセスが必要。\\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### 3. **医療コンテンツ生成プラットフォーム**\\n'\n",
      " '生成AIを活用して、患者向けの医療情報や教育コンテンツを自動生成するプラットフォームを提供します。たとえば、特定の病気に関する説明や治療法の概要を、患者の理解度に応じてカスタマイズして提供するサービスです。\\n'\n",
      " '\\n'\n",
      " '- **ビジネスメリット**: 医療情報へのアクセスを容易にし、患者の理解を深める。\\n'\n",
      " '- **倫理的配慮**: 提供する情報の正確性を保証するため、医療専門家による監修が必要。誤情報の拡散を防ぐ仕組みを構築。\\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### 4. **臨床試験の効率化**\\n'\n",
      " '生成AIを活用して、臨床試験のデザインや被験者の選定を効率化するサービスを提供します。AIが過去の試験データを分析し、最適な試験設計や対象者のリクルーティング戦略を提案します。\\n'\n",
      " '\\n'\n",
      " '- **ビジネスメリット**: 臨床試験のコスト削減と成功率の向上。\\n'\n",
      " '- **倫理的配慮**: 被験者のプライバシー保護、AIによるバイアスの排除。\\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### 5. **医療画像解析の自動化**\\n'\n",
      " '生成AIを用いて、X線、MRI、CTスキャンなどの医療画像を解析し、異常を検出するサービスを提供します。これにより、医師の診断を補助し、早期発見を促進します。\\n'\n",
      " '\\n'\n",
      " '- **ビジネスメリット**: 医療画像解析の効率化、診断の迅速化。\\n'\n",
      " '- **倫理的配慮**: 誤検出や見逃しのリスクを最小化するための品質管理。AIの結果に対する医師の最終確認を必須とする。\\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### 6. **メンタルヘルスケアのサポート**\\n'\n",
      " '生成AIを活用したチャットボットやアプリを開発し、メンタルヘルスケアのサポートを提供します。たとえば、ストレス管理や不安軽減のための対話型ツールを提供することが考えられます。\\n'\n",
      " '\\n'\n",
      " '- **ビジネスメリット**: メンタルヘルスケアの需要増加に対応。\\n'\n",
      " '- **倫理的配慮**: 深刻な症状を抱える患者には専門家への相談を促す仕組みを導入。AIが提供するアドバイスの限界を明示。\\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### 7. **医療翻訳サービス**\\n'\n",
      " '生成AIを活用して、医療文書や診断結果を多言語に翻訳するサービスを提供します。これにより、言語の壁を超えた医療アクセスを実現します。\\n'\n",
      " '\\n'\n",
      " '- **ビジネスメリット**: グローバル化する医療市場での需要増加。\\n'\n",
      " '- **倫理的配慮**: 翻訳の正確性を保証するため、専門家によるレビューを組み込む。\\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### 総括\\n'\n",
      " '生成AIを医療業界で活用するビジネスには多くの可能性がありますが、データのプライバシー保護、AIの透明性、倫理的な責任を十分に考慮する必要があります。特に、医療分野では人命に関わるため、AIの導入には慎重なアプローチが求められます。']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(result['messages'])\n",
    "# for m in result['messages']:\n",
    "#     pprint(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206c874d",
   "metadata": {},
   "source": [
    "\n",
    "マルチエージェントの構成にしているわけではないので、あくまで与えられた複数のエキスパートから一つを選んで回答を生成し、問題なければそこで回答になるというグラフに過ぎない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4629d03c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5198ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
